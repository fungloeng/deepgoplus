#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åˆ†æé¢„æµ‹ç»“æœï¼Œæ£€æŸ¥æ•°æ®æ³„éœ²å¹¶åˆ†åˆ«è¯„ä¼°DIAMONDå’Œæ·±åº¦å­¦ä¹ æ¨¡å‹

ç”¨æ³•:
python src/evaluation/analyze_predictions.py \
    --pred-file galaxy/results/mf_test_preds_galaxy_deepgoplus_run1.tsv \
    --diamond-file galaxy/results/mf_test_preds_galaxy_deepgoplus_run1_diamond_only.tsv \
    --deep-file galaxy/results/mf_test_preds_galaxy_deepgoplus_run1_deep_only.tsv \
    --true-file galaxy/MF_test_data.pkl \
    --train-file galaxy/MF_train_data.pkl \
    --out-file galaxy/results/analysis_report.txt
"""

import click as ck
import pandas as pd
import sys
import os
from collections import defaultdict
import logging

# Add project root to path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)
# Add src directory to path for imports
src_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
if src_path not in sys.path:
    sys.path.insert(0, src_path)

from evaluate_predictions import parse_prediction_file, load_true_labels, calculate_metrics
from deepgoplus.utils import Ontology

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')


def check_data_leakage(test_file, train_file):
    """æ£€æŸ¥æµ‹è¯•é›†å’Œè®­ç»ƒé›†æ˜¯å¦æœ‰é‡å """
    logging.info("Checking for data leakage...")
    
    test_df = pd.read_pickle(test_file)
    train_df = pd.read_pickle(train_file)
    
    test_proteins = set(test_df['proteins'].values)
    train_proteins = set(train_df['proteins'].values)
    
    overlap = test_proteins & train_proteins
    overlap_ratio = len(overlap) / len(test_proteins) if len(test_proteins) > 0 else 0
    
    return {
        'test_count': len(test_proteins),
        'train_count': len(train_proteins),
        'overlap_count': len(overlap),
        'overlap_ratio': overlap_ratio,
        'overlap_proteins': list(overlap)[:10]  # First 10 for display
    }


def analyze_model_contribution(combined_preds, diamond_preds, deep_preds, true_labels, go, ont):
    """åˆ†æDIAMONDå’Œæ·±åº¦å­¦ä¹ æ¨¡å‹çš„è´¡çŒ®"""
    logging.info("Analyzing model contributions...")
    
    # Count predictions from each model
    diamond_only = 0
    deep_only = 0
    both = 0
    diamond_total = 0
    deep_total = 0
    
    for prot_id in combined_preds:
        combined_gos = set(combined_preds[prot_id].keys())
        diamond_gos = set(diamond_preds.get(prot_id, {}).keys())
        deep_gos = set(deep_preds.get(prot_id, {}).keys())
        
        diamond_total += len(diamond_gos)
        deep_total += len(deep_gos)
        
        diamond_only_gos = diamond_gos - deep_gos
        deep_only_gos = deep_gos - diamond_gos
        both_gos = diamond_gos & deep_gos
        
        diamond_only += len(diamond_only_gos)
        deep_only += len(deep_only_gos)
        both += len(both_gos)
    
    # Calculate average scores
    diamond_avg_score = 0.0
    deep_avg_score = 0.0
    diamond_count = 0
    deep_count = 0
    
    for prot_id in diamond_preds:
        for go_id, score in diamond_preds[prot_id].items():
            diamond_avg_score += score
            diamond_count += 1
    
    for prot_id in deep_preds:
        for go_id, score in deep_preds[prot_id].items():
            deep_avg_score += score
            deep_count += 1
    
    diamond_avg_score = diamond_avg_score / diamond_count if diamond_count > 0 else 0
    deep_avg_score = deep_avg_score / deep_count if deep_count > 0 else 0
    
    return {
        'diamond_only_count': diamond_only,
        'deep_only_count': deep_only,
        'both_count': both,
        'diamond_total': diamond_total,
        'deep_total': deep_total,
        'diamond_avg_score': diamond_avg_score,
        'deep_avg_score': deep_avg_score,
        'diamond_ratio': diamond_total / (diamond_total + deep_total) if (diamond_total + deep_total) > 0 else 0,
        'deep_ratio': deep_total / (diamond_total + deep_total) if (diamond_total + deep_total) > 0 else 0
    }


@ck.command()
@ck.option('--pred-file', '-pf', required=True, help='ç»„åˆé¢„æµ‹ç»“æœæ–‡ä»¶')
@ck.option('--diamond-file', '-df', default=None, help='DIAMONDå•ç‹¬é¢„æµ‹æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰')
@ck.option('--deep-file', '-deep', default=None, help='æ·±åº¦å­¦ä¹ æ¨¡å‹å•ç‹¬é¢„æµ‹æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰')
@ck.option('--true-file', '-tf', required=True, help='çœŸå®æ ‡ç­¾PKLæ–‡ä»¶')
@ck.option('--train-file', '-trf', default=None, help='è®­ç»ƒæ•°æ®PKLæ–‡ä»¶ï¼ˆç”¨äºæ£€æŸ¥æ•°æ®æ³„éœ²ï¼‰')
@ck.option('--go-file', '-gf', default='go.obo', help='GOæœ¬ä½“æ–‡ä»¶')
@ck.option('--ont', '-o', default=None, type=ck.Choice(['mf', 'cc', 'bp', 'pf']), 
           help='æœ¬ä½“ç±»å‹')
@ck.option('--out-file', '-of', required=True, help='è¾“å‡ºåˆ†ææŠ¥å‘Šæ–‡ä»¶')
def main(pred_file, diamond_file, deep_file, true_file, train_file, go_file, ont, out_file):
    """åˆ†æé¢„æµ‹ç»“æœï¼Œæ£€æŸ¥æ•°æ®æ³„éœ²å¹¶è¯„ä¼°å„æ¨¡å‹"""
    
    # Resolve paths
    if not os.path.isabs(go_file):
        true_dir = os.path.dirname(true_file)
        go_file_path = os.path.join(true_dir, go_file)
        if os.path.exists(go_file_path):
            go_file = go_file_path
        else:
            go_file = os.path.abspath(go_file)
    
    if not os.path.exists(pred_file):
        logging.error(f"é¢„æµ‹æ–‡ä»¶ä¸å­˜åœ¨: {pred_file}")
        sys.exit(1)
    if not os.path.exists(true_file):
        logging.error(f"çœŸå®æ ‡ç­¾æ–‡ä»¶ä¸å­˜åœ¨: {true_file}")
        sys.exit(1)
    if not os.path.exists(go_file):
        logging.error(f"GOæ–‡ä»¶ä¸å­˜åœ¨: {go_file}")
        sys.exit(1)
    
    logging.info("Loading GO ontology...")
    go = Ontology(go_file, with_rels=True)
    
    # Load predictions
    logging.info("Loading combined predictions...")
    combined_preds = parse_prediction_file(pred_file)
    
    diamond_preds = {}
    deep_preds = {}
    
    if diamond_file and os.path.exists(diamond_file):
        logging.info("Loading DIAMOND predictions...")
        diamond_preds = parse_prediction_file(diamond_file)
    
    if deep_file and os.path.exists(deep_file):
        logging.info("Loading DeepGO predictions...")
        deep_preds = parse_prediction_file(deep_file)
    
    # Load true labels
    logging.info("Loading true labels...")
    true_labels = load_true_labels(true_file, ont, go)
    
    # Check data leakage
    leakage_info = None
    if train_file and os.path.exists(train_file):
        leakage_info = check_data_leakage(true_file, train_file)
    
    # Calculate metrics for combined predictions
    logging.info("Calculating metrics for combined predictions...")
    combined_metrics = calculate_metrics(combined_preds, true_labels, go, ont)
    
    # Calculate metrics for separate models if available
    diamond_metrics = None
    deep_metrics = None
    if diamond_preds:
        logging.info("Calculating metrics for DIAMOND predictions...")
        diamond_metrics = calculate_metrics(diamond_preds, true_labels, go, ont)
    
    if deep_preds:
        logging.info("Calculating metrics for DeepGO predictions...")
        deep_metrics = calculate_metrics(deep_preds, true_labels, go, ont)
    
    # Analyze model contribution
    contribution_info = None
    if diamond_preds and deep_preds:
        contribution_info = analyze_model_contribution(
            combined_preds, diamond_preds, deep_preds, true_labels, go, ont
        )
    
    # Write report
    logging.info(f"Writing analysis report to {out_file}...")
    with open(out_file, 'w') as f:
        f.write("=" * 80 + "\n")
        f.write("DeepGOPlus é¢„æµ‹ç»“æœåˆ†ææŠ¥å‘Š\n")
        f.write("=" * 80 + "\n\n")
        
        if ont:
            f.write(f"æœ¬ä½“ (Ontology): {ont.upper()}\n\n")
        else:
            f.write(f"æœ¬ä½“ (Ontology): å…¨éƒ¨\n\n")
        
        # Data leakage check
        if leakage_info:
            f.write("=" * 80 + "\n")
            f.write("æ•°æ®æ³„éœ²æ£€æŸ¥ (Data Leakage Check)\n")
            f.write("=" * 80 + "\n")
            f.write(f"æµ‹è¯•é›†è›‹ç™½è´¨æ•°é‡: {leakage_info['test_count']}\n")
            f.write(f"è®­ç»ƒé›†è›‹ç™½è´¨æ•°é‡: {leakage_info['train_count']}\n")
            f.write(f"é‡å è›‹ç™½è´¨æ•°é‡: {leakage_info['overlap_count']}\n")
            f.write(f"é‡å æ¯”ä¾‹: {leakage_info['overlap_ratio']:.2%}\n")
            if leakage_info['overlap_count'] > 0:
                f.write(f"\nâš ï¸  è­¦å‘Š: å‘ç° {leakage_info['overlap_count']} ä¸ªé‡å è›‹ç™½è´¨ï¼\n")
                f.write(f"è¿™å¯èƒ½å¯¼è‡´è¯„ä¼°ç»“æœè™šé«˜ã€‚\n")
                if leakage_info['overlap_proteins']:
                    f.write(f"ç¤ºä¾‹é‡å è›‹ç™½è´¨: {', '.join(leakage_info['overlap_proteins'])}\n")
            else:
                f.write(f"\nâœ“ æœªå‘ç°æ•°æ®æ³„éœ²\n")
            f.write("\n")
        
        # Model contribution analysis
        if contribution_info:
            f.write("=" * 80 + "\n")
            f.write("æ¨¡å‹è´¡çŒ®åˆ†æ (Model Contribution Analysis)\n")
            f.write("=" * 80 + "\n")
            f.write(f"DIAMOND å•ç‹¬é¢„æµ‹æ•°: {contribution_info['diamond_only_count']}\n")
            f.write(f"DeepGO å•ç‹¬é¢„æµ‹æ•°: {contribution_info['deep_only_count']}\n")
            f.write(f"ä¸¤è€…éƒ½é¢„æµ‹çš„æ•°é‡: {contribution_info['both_count']}\n")
            f.write(f"\nDIAMOND æ€»é¢„æµ‹æ•°: {contribution_info['diamond_total']}\n")
            f.write(f"DeepGO æ€»é¢„æµ‹æ•°: {contribution_info['deep_total']}\n")
            f.write(f"DIAMOND é¢„æµ‹æ¯”ä¾‹: {contribution_info['diamond_ratio']:.2%}\n")
            f.write(f"DeepGO é¢„æµ‹æ¯”ä¾‹: {contribution_info['deep_ratio']:.2%}\n")
            f.write(f"\nDIAMOND å¹³å‡åˆ†æ•°: {contribution_info['diamond_avg_score']:.4f}\n")
            f.write(f"DeepGO å¹³å‡åˆ†æ•°: {contribution_info['deep_avg_score']:.4f}\n")
            f.write("\n")
        
        # Combined metrics
        f.write("=" * 80 + "\n")
        f.write("ç»„åˆæ¨¡å‹è¯„ä¼°æŒ‡æ ‡ (Combined Model Metrics)\n")
        f.write("=" * 80 + "\n")
        f.write(f"Fmax: {combined_metrics['fmax']:.4f} (é˜ˆå€¼: {combined_metrics['fmax_threshold']:.3f})\n")
        f.write(f"AUPR: {combined_metrics['aupr']:.4f}\n")
        f.write(f"æ€»ä½“ç²¾ç¡®ç‡: {combined_metrics['overall_precision']:.4f}\n")
        f.write(f"æ€»ä½“å¬å›ç‡: {combined_metrics['overall_recall']:.4f}\n")
        f.write(f"å¹³å‡ç²¾ç¡®ç‡: {combined_metrics['avg_precision']:.4f}\n")
        f.write(f"å¹³å‡å¬å›ç‡: {combined_metrics['avg_recall']:.4f}\n")
        f.write(f"å¹³å‡F1: {combined_metrics['avg_f1']:.4f}\n")
        f.write("\n")
        
        # DIAMOND metrics
        if diamond_metrics:
            f.write("=" * 80 + "\n")
            f.write("DIAMOND æ¨¡å‹è¯„ä¼°æŒ‡æ ‡ (DIAMOND Model Metrics)\n")
            f.write("=" * 80 + "\n")
            f.write(f"Fmax: {diamond_metrics['fmax']:.4f} (é˜ˆå€¼: {diamond_metrics['fmax_threshold']:.3f})\n")
            f.write(f"AUPR: {diamond_metrics['aupr']:.4f}\n")
            f.write(f"æ€»ä½“ç²¾ç¡®ç‡: {diamond_metrics['overall_precision']:.4f}\n")
            f.write(f"æ€»ä½“å¬å›ç‡: {diamond_metrics['overall_recall']:.4f}\n")
            f.write(f"å¹³å‡ç²¾ç¡®ç‡: {diamond_metrics['avg_precision']:.4f}\n")
            f.write(f"å¹³å‡å¬å›ç‡: {diamond_metrics['avg_recall']:.4f}\n")
            f.write(f"å¹³å‡F1: {diamond_metrics['avg_f1']:.4f}\n")
            f.write("\n")
        
        # DeepGO metrics
        if deep_metrics:
            f.write("=" * 80 + "\n")
            f.write("DeepGO æ¨¡å‹è¯„ä¼°æŒ‡æ ‡ (DeepGO Model Metrics)\n")
            f.write("=" * 80 + "\n")
            f.write(f"Fmax: {deep_metrics['fmax']:.4f} (é˜ˆå€¼: {deep_metrics['fmax_threshold']:.3f})\n")
            f.write(f"AUPR: {deep_metrics['aupr']:.4f}\n")
            f.write(f"æ€»ä½“ç²¾ç¡®ç‡: {deep_metrics['overall_precision']:.4f}\n")
            f.write(f"æ€»ä½“å¬å›ç‡: {deep_metrics['overall_recall']:.4f}\n")
            f.write(f"å¹³å‡ç²¾ç¡®ç‡: {deep_metrics['avg_precision']:.4f}\n")
            f.write(f"å¹³å‡å¬å›ç‡: {deep_metrics['avg_recall']:.4f}\n")
            f.write(f"å¹³å‡F1: {deep_metrics['avg_f1']:.4f}\n")
            f.write("\n")
        
        # Summary and recommendations
        f.write("=" * 80 + "\n")
        f.write("åˆ†ææ€»ç»“ (Summary)\n")
        f.write("=" * 80 + "\n")
        
        if leakage_info and leakage_info['overlap_ratio'] > 0.01:
            f.write("âš ï¸  å‘ç°æ•°æ®æ³„éœ²é—®é¢˜ï¼æµ‹è¯•é›†å’Œè®­ç»ƒé›†æœ‰é‡å ã€‚\n")
            f.write("   å»ºè®®ï¼šé‡æ–°åˆ’åˆ†æ•°æ®é›†ï¼Œç¡®ä¿æµ‹è¯•é›†å’Œè®­ç»ƒé›†å®Œå…¨åˆ†ç¦»ã€‚\n\n")
        
        if diamond_metrics and deep_metrics:
            if diamond_metrics['fmax'] > deep_metrics['fmax'] * 1.1:
                f.write("ğŸ“Š DIAMOND æ¨¡å‹è¡¨ç°æ˜æ˜¾ä¼˜äº DeepGO æ¨¡å‹ã€‚\n")
                f.write("   è¿™å¯èƒ½è¡¨æ˜ï¼š\n")
                f.write("   - æµ‹è¯•é›†ä¸è®­ç»ƒé›†åºåˆ—ç›¸ä¼¼åº¦è¾ƒé«˜\n")
                f.write("   - æ·±åº¦å­¦ä¹ æ¨¡å‹éœ€è¦æ›´å¤šè®­ç»ƒæˆ–è°ƒä¼˜\n\n")
            elif deep_metrics['fmax'] > diamond_metrics['fmax'] * 1.1:
                f.write("ğŸ“Š DeepGO æ¨¡å‹è¡¨ç°æ˜æ˜¾ä¼˜äº DIAMOND æ¨¡å‹ã€‚\n")
                f.write("   è¿™è¡¨æ˜æ·±åº¦å­¦ä¹ æ¨¡å‹å­¦åˆ°äº†åºåˆ—ç›¸ä¼¼æ€§ä¹‹å¤–çš„ç‰¹å¾ã€‚\n\n")
            else:
                f.write("ğŸ“Š ä¸¤ä¸ªæ¨¡å‹è¡¨ç°ç›¸è¿‘ï¼Œç»„åˆä½¿ç”¨å¯ä»¥äº’è¡¥ã€‚\n\n")
        
        f.write("=" * 80 + "\n")
    
    logging.info("Analysis complete!")


if __name__ == '__main__':
    main()

